#!/usr/bin/env php
<?php
/**
 * Download and validate json files, and handle backups if changes are detected.
 */
require 'vendor/autoload.php';

use Garden\Cli\Cli;
use Httpful\Request;

$cli = new Cli();
$cli->description("Downloads json files from the official site, validates them, replaces the old files, and handles backups if changes are detected.")
    ->opt('output:o', 'Path to save files', true)
    ->opt('proxy:p', 'Proxy server like \"proxy:3128\"', false)
    ->opt('base:b', 'Base download url', true);
$args = $cli->parse($argv, true);

$destinationPath = $args->getOpt('output');
$currentPath = $destinationPath . '/current';
$backupPath = $destinationPath . '/backups';

// Ensure the current directory exists
if (!is_dir($currentPath) && !mkdir($currentPath, 0777, true) && !is_dir($currentPath)) {
    echo $cli->red("Failed to create the current directory at $currentPath\n");
    exit(1);
}

$baseDomain = $args->getOpt('base');
$proxy = $args->getOpt('proxy') ?: getenv('HTTP_PROXY');
$client = Request::init()->withoutAutoParsing()->followRedirects()->timeout(30);

if ($proxy) {
    $client->useProxy($proxy);
}

Request::ini($client);

$downloads = [
    [
        'url' => '/export/standorte/json/',
        'file' => 'locations_de.json',
    ],
    [
        'url' => '/export/standorte/json/en/',
        'file' => 'locations_en.json',
    ],
    [
        'url' => '/export/dienstleistungen/json/',
        'file' => 'services_de.json',
    ],
    [
        'url' => '/export/dienstleistungen/json/en/',
        'file' => 'services_en.json',
    ],
    [
        'url' => '/export/themen/json/',
        'file' => 'topic_de.json',
    ],
    [
        'url' => '/export/behoerden/json/',
        'file' => 'authority_de.json',
    ],
    [
        'url' => '/export/settings/json/',
        'file' => 'settings.json',
    ],
];

// Validate and download new files, determine if backup is necessary
$backupRequired = false;
foreach ($downloads as $download) {
    $destFile = $currentPath . '/' . $download['file'];
    $request = Request::get($baseDomain . $download['url'])->send();
    
    if ($request->code !== 200 || (isset($request->body->error) && $request->body->error)) {
        echo $cli->red("Failed to download or validate {$download['file']}\n");
        continue;
    }

    $newContent = $request->raw_body;
    if (file_exists($destFile) && md5_file($destFile) !== md5($newContent)) {
        $backupRequired = true;
    }
    
    file_put_contents($destFile, $newContent);
}

// Perform backup if necessary
if ($backupRequired) {
    $timestamp = date('Y-m-d');
    $backupDir = $backupPath . '/' . $timestamp;
    
    if (!mkdir($backupDir, 0777, true) && !is_dir($backupDir)) {
        echo $cli->red("Failed to create backup directory at $backupDir\n");
        exit(1);
    }
    
    // Copy updated files to backup
    foreach (glob($currentPath . '/*.json') as $file) {
        if (!copy($file, $backupDir . '/' . basename($file))) {
            echo $cli->red("Failed to backup $file\n");
        }
    }
}

// Delete backups older than 7 days
$sevenDaysAgo = time() - (7 * 24 * 60 * 60); // 7 days in seconds

foreach (glob($backupPath . '/*', GLOB_ONLYDIR) as $dir) {
    if (filemtime($dir) < $sevenDaysAgo) {
        // Recursively delete directory contents
        foreach (new RecursiveIteratorIterator(new RecursiveDirectoryIterator($dir, FilesystemIterator::SKIP_DOTS), RecursiveIteratorIterator::CHILD_FIRST) as $item) {
            $item->isDir() ? rmdir($item->getRealPath()) : unlink($item->getRealPath());
        }
        // Delete the backup directory
        rmdir($dir);
        echo "Deleted old backup: $dir\n";
    }
}
echo "Downloads and backups (if necessary) completed.\n";